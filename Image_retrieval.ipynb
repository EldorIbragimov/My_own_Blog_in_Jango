{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Image Retrieval network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "from torchvision import transforms\n",
    "import copy\n",
    "import os\n",
    "import h5py\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network to extract the features\n",
    "class MyResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, resnet, transform_input=False):\n",
    "        super(MyResNetFeatureExtractor, self).__init__()\n",
    "        self.transform_input = transform_input\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        # self.fc = resnet.fc\n",
    "        # stop where you want, copy paste from the model def\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.transform_input:\n",
    "            x = x.clone()\n",
    "            x[0] = x[0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x[1] = x[1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x[2] = x[2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "        # 299 x 299 x 3\n",
    "        x = self.conv1(x)\n",
    "        # 149 x 149 x 32\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        # 147 x 147 x 32\n",
    "        x = self.layer1(x)\n",
    "        # 147 x 147 x 64\n",
    "        x = self.layer2(x)\n",
    "        # 73 x 73 x 64\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=7, stride=7)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained model from by using torchvision package\n",
    "model = torchvision.models.resnet50(pretrained = True) # resnet 50 model is imported\n",
    "\n",
    "# set the model train False since we are using our feature extraction network \n",
    "model.train(False)\n",
    "\n",
    "# Set our model with pre-trained model \n",
    "my_resnet = MyResNetFeatureExtractor(model).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BigBen09.jpg',\n",
       " 'Herend08.jpg',\n",
       " 'Cathedral08.jpg',\n",
       " 'Cathedral05.jpg',\n",
       " 'BigBen05.jpg',\n",
       " 'None10.jpg',\n",
       " 'BrandenburgGate03.jpg',\n",
       " 'CommandoMemorial10.jpg',\n",
       " 'NotreDameDesAanges03.jpg',\n",
       " 'BrandenburgGate10.jpg',\n",
       " 'AmidaBuddha.jpg',\n",
       " 'BigBen04.jpg',\n",
       " 'None02.jpg',\n",
       " 'BigBen01.jpg',\n",
       " 'GuildHouses08.jpg',\n",
       " 'Basilique08.jpg',\n",
       " 'Herend04.jpg',\n",
       " 'Cathedral07.jpg',\n",
       " 'Herend.jpg',\n",
       " 'BigBen03.jpg',\n",
       " 'BrandenburgGate02.jpg',\n",
       " 'None04.jpg',\n",
       " 'None03.jpg',\n",
       " 'None06.jpg',\n",
       " 'Cathedral04.jpg',\n",
       " 'AmidaBuddha10.jpg',\n",
       " 'AmidaBuddha04.jpg',\n",
       " 'CommandoMemorial07.jpg',\n",
       " 'Basilique01.jpg',\n",
       " 'BrandenburgGate05.jpg',\n",
       " 'Basilique04.jpg',\n",
       " 'Herend07.jpg',\n",
       " 'NotreDameDesAanges04.jpg',\n",
       " 'AmidaBuddha02.jpg',\n",
       " 'Cathedral06.jpg',\n",
       " 'GuildHouses05.jpg',\n",
       " 'CommandoMemorial09.jpg',\n",
       " 'Cathedral02.jpg',\n",
       " 'None07.jpg',\n",
       " 'Basilique.jpg',\n",
       " 'NotreDameDesAanges10.jpg',\n",
       " 'NotreDameDesAanges05.jpg',\n",
       " 'BrandenburgGate01.jpg',\n",
       " 'CommandoMemorial08.jpg',\n",
       " 'Basilique06.jpg',\n",
       " 'CommandoMemorial04.jpg',\n",
       " 'GuildHouses02.jpg',\n",
       " 'BigBen06.jpg',\n",
       " 'AmidaBuddha01.jpg',\n",
       " 'AmidaBuddha07.jpg',\n",
       " 'GuildHouses01.jpg',\n",
       " 'GuildHouses04.jpg',\n",
       " 'GuildHouses03.jpg',\n",
       " 'NotreDameDesAanges06.jpg',\n",
       " 'AmidaBuddha09.jpg',\n",
       " 'GuildHouses10.jpg',\n",
       " 'Basilique05.jpg',\n",
       " 'AmidaBuddha06.jpg',\n",
       " 'Cathedral.jpg',\n",
       " 'BigBen10.jpg',\n",
       " 'Herend02.jpg',\n",
       " 'GuildHouses09.jpg',\n",
       " 'CommandoMemorial01.jpg',\n",
       " 'Basilique02.jpg',\n",
       " 'BrandenburgGate07.jpg',\n",
       " 'Basilique10.jpg',\n",
       " 'NotreDameDesAanges01.jpg',\n",
       " 'NotreDameDesAanges09.jpg',\n",
       " 'AmidaBuddha05.jpg',\n",
       " 'NotreDameDesAanges07.jpg',\n",
       " 'Herend03.jpg',\n",
       " 'BrandenburgGate09.jpg',\n",
       " 'CommandoMemorial06.jpg',\n",
       " 'CommandoMemorial02.jpg',\n",
       " 'BrandenburgGate08.jpg',\n",
       " 'BigBen07.jpg',\n",
       " 'BigBen.jpg',\n",
       " 'GuildHouses07.jpg',\n",
       " 'Herend06.jpg',\n",
       " 'Basilique07.jpg',\n",
       " 'BrandenburgGate06.jpg',\n",
       " 'NotreDameDes Anges.jpg',\n",
       " 'Herend05.jpg',\n",
       " 'None09.jpg',\n",
       " 'CommandoMemorial.jpg',\n",
       " 'BigBen08.jpg',\n",
       " 'None08.jpg',\n",
       " 'Herend09.jpg',\n",
       " 'NotreDameDesAanges02.jpg',\n",
       " 'Basilique09.jpg',\n",
       " 'Cathedral03.jpg',\n",
       " 'GuildHouses.jpg',\n",
       " 'Basilique03.jpg',\n",
       " 'Cathedral01.jpg',\n",
       " 'CommandoMemorial05.jpg',\n",
       " 'NotreDameDesAanges08.jpg',\n",
       " 'BigBen02.jpg',\n",
       " 'AmidaBuddha03.jpg',\n",
       " 'GuildHouses06.jpg',\n",
       " 'CommandoMemorial03.jpg',\n",
       " 'BrandenburgGate .jpg',\n",
       " 'BrandenburgGate04.jpg',\n",
       " 'None05.jpg',\n",
       " 'Herend01.jpg',\n",
       " 'None11.jpg',\n",
       " 'Herend10.jpg',\n",
       " 'None01.jpg',\n",
       " 'Cathedral09.jpg',\n",
       " 'Cathedral10.jpg',\n",
       " 'AmidaBuddha08.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read images training images from the directory\n",
    "root = './index/'\n",
    "list_imgs_names = os.listdir(root)\n",
    "list_imgs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"The number of train images:\",len(list_imgs_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature extraction with CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete in 4.01s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "# read images images from a directory\n",
    "root = './index/'\n",
    "list_imgs_names = os.listdir(root)\n",
    "list_imgs_names\n",
    "# create an array to store features \n",
    "N = len(list_imgs_names)\n",
    "fea_all = np.zeros((N, 2048))\n",
    "# define empy array to store image names\n",
    "image_all = []\n",
    "# extract features \n",
    "for ind, img_name in enumerate(list_imgs_names):\n",
    "    #print(img_name)\n",
    "    img_path = os.path.join(root, img_name)\n",
    "    image_np = Image.open(img_path)\n",
    "    image_np = np.array(image_np)\n",
    "    image_np = resize(image_np, (224, 224))\n",
    "    image_np = torch.from_numpy(image_np).permute(2, 0, 1).float()\n",
    "    image_np = Variable(image_np.unsqueeze(0))   #bs, c, h, w\n",
    "    image_np = image_np.cuda()\n",
    "    fea = my_resnet(image_np)\n",
    "    fea = fea.squeeze()\n",
    "    fea = fea.cpu().data.numpy()\n",
    "    fea = fea.reshape((1, 2048))\n",
    "    fea = fea / LA.norm(fea)\n",
    "    fea_all[ind] = fea\n",
    "    image_all.append(img_name)\n",
    "\n",
    "time_elapsed = time.time() - since \n",
    "\n",
    "print('Feature extraction complete in {:.02f}s'.format(time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving extracted features as a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_all = np.array(fea_all)\n",
    "img_all = np.array(image_all)\n",
    "h5f = h5py.File('featsss.h5', 'w')\n",
    "h5f.create_dataset('dataset_1', data=fea_all)\n",
    "#h5f.create_dataset('dataset_2', data=img_all)\n",
    "\n",
    "img_all = [n.encode(\"ascii\", \"ignore\") for n in image_all]\n",
    "h5f.create_dataset('dataset_2', (len(img_all),1), data=img_all)\n",
    "\n",
    "h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('featsss.h5', 'r')\n",
    "fea_all = h5f['dataset_1'][:]\n",
    "im_all = h5f['dataset_2'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Herend08.j'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = im_all[1][0].decode('utf-8')\n",
    "a\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No conversion path for dtype: dtype('<U24')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2392cd08e504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'featsCNNNNm.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfea_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \"\"\"\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: No conversion path for dtype: dtype('<U24')"
     ]
    }
   ],
   "source": [
    "fea_all = np.array(fea_all)\n",
    "h5f = h5py.File('featsCNNNNm.h5', 'w')\n",
    "h5f.create_dataset('dataset_1', data=fea_all)\n",
    "h5f.create_dataset('dataset_2', data=image_all)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_all = np.array(fea_all)\n",
    "scores  = np.dot(fea_all, fea_all.T)\n",
    "sort_ind = np.argsort(scores)[0][::-1]\n",
    "scores = scores[0, sort_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxres = 10\n",
    "imlist = [image_all[index] for i,index in enumerate(sort_ind[0:maxres])]\n",
    "print (\"top %d images in order are: \" %maxres, imlist)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(imlist)):\n",
    "    sample = imlist[i]\n",
    "    img = mpimg.imread('./index' + '/' + sample)\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    ax.autoscale()\n",
    "    #plt.tight_layout()\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    ax.set_title('{:.3f}%'.format(scores[i]))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
